{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distribution of scores and filter data within score ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mroemmele/elaboration/eval_items/spacy_word_prob_sampled/cohesion_scores_len3.json') as f:\n",
    "    score_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tokens = 3\n",
    "max_tokens = 3\n",
    "max_stop_words = 1\n",
    "min_score = hard_range[0]\n",
    "max_score = hard_range[1]\n",
    "\n",
    "qualified_items = []\n",
    "qualified_scores = []\n",
    "\n",
    "for idx, item in enumerate(score_data):\n",
    "#     import pdb;pdb.set_trace()\n",
    "    # Check duplicate tokens\n",
    "    tokens_are_unique = len(item['tokens']) == len(set(item['tokens']))\n",
    "\n",
    "    n_tokens = len(item['tokens'])\n",
    "    are_qualified_tokens = numpy.all(~numpy.array(\n",
    "        [values for attr, values in item.items()\n",
    "         if attr in ('is_spacy_oov', 'is_bert_oov', 'is_punct',\n",
    "                     'is_space', 'is_digit', 'is_entity')]))\n",
    "    n_stop_words = sum(item['is_stop'])\n",
    "    \n",
    "    tokens_are_eligible = (are_qualified_tokens &\n",
    "                           tokens_are_unique &\n",
    "                           (min_tokens <= n_tokens <= max_tokens) &\n",
    "                           (n_stop_words <= max_stop_words))\n",
    "    \n",
    "    score = numpy.array(item['scores']).mean()\n",
    "    is_in_score_range = min_score <= score <= max_score\n",
    "\n",
    "\n",
    "    if tokens_are_eligible & is_in_score_range:\n",
    "        #print(\"qualified:\", item['tokens'], score)\n",
    "        qualified_items.append(\" \".join(item['tokens']))\n",
    "        qualified_scores.append(score)\n",
    "        \n",
    "#     if idx == 100000:\n",
    "#         break\n",
    "print(len(qualified_items), \"qualified items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/mroemmele/elaboration/eval_items/bookcorpus_test_no_quotes/hard/mintok{}_maxtok{}_maxstop{}_minscore{}_maxscore{}.txt\".format(\n",
    "min_tokens, max_tokens, max_stop_words, min_score, max_score)\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"\\n\".join(qualified_items))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score distribution stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_range = (numpy.percentile(qualified_scores, 0), numpy.percentile(qualified_scores, 5))\n",
    "medium_range = (numpy.percentile(qualified_scores, 49.5), numpy.percentile(qualified_scores, 50.5))\n",
    "easy_range = (numpy.percentile(qualified_scores, 99.5), numpy.percentile(qualified_scores, 100))\n",
    "\n",
    "easy_range, medium_range, hard_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_range = (numpy.percentile(qualified_scores, 0), numpy.percentile(qualified_scores, 10))\n",
    "medium_range = (numpy.percentile(qualified_scores, 45), numpy.percentile(qualified_scores, 55))\n",
    "easy_range = (numpy.percentile(qualified_scores, 90), numpy.percentile(qualified_scores, 100))\n",
    "\n",
    "easy_range, medium_range, hard_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply filter to existing generated inputs/sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "from profanity_filter import ProfanityFilter\n",
    "\n",
    "spacy_model = spacy.load('en')\n",
    "profanity_filter = ProfanityFilter(nlps={'en': spacy_model})\n",
    "spacy_model.add_pipe(profanity_filter.spacy_component, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_items_dir = \"/home/mroemmele/elaboration/eval_items/bookcorpus_test_no_quotes/input_items/\"\n",
    "generated_sents_dir = \"/home/mroemmele/elaboration/eval_items/bookcorpus_test_no_quotes/generated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(input_items_dir, 'PG_input_items/hard-mintok3_maxtok3_maxstop1_minscore8.540907714404966e-08_maxscore8.156606483566975e-06.txt')) as f:\n",
    "    orig_input_words = [line.strip().split(\" \") for line in f]\n",
    "    \n",
    "with open(os.path.join(generated_sents_dir, 'PG_input_items/hard.txt')) as f:\n",
    "    orig_gen_sents = [line.strip().split(\"\\t\") for line in f]\n",
    "    \n",
    "list(zip(orig_input_words, orig_gen_sents))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_input_words = []\n",
    "filtered_gen_sents = []\n",
    "for idx, (input_words, gen_sents) in enumerate(zip(orig_input_words, orig_gen_sents)):\n",
    "    # There must be 5 generated sentences\n",
    "    if len(gen_sents) < 5:\n",
    "        print(\"Too few generated sentences in item num {}: {}\".format(idx + 1, gen_sents))\n",
    "        continue\n",
    "#     # Remove items where at least one sentence is profane\n",
    "#     contains_profane_sent = False\n",
    "#     for sent in gen_sents:\n",
    "#         spacy_sent = spacy_model(sent)\n",
    "#         if spacy_sent._.is_profane:\n",
    "#             print(\"profane sentence for input item {}: {}\".format(idx, sent))\n",
    "#             contains_profane_sent = True\n",
    "#             break\n",
    "#     if not contains_profane_sent:\n",
    "    filtered_input_words.append(input_words)\n",
    "    filtered_gen_sents.append(gen_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_input_words), len(filtered_input_words), len(orig_gen_sents), len(filtered_gen_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gen_sents[-2:], filtered_input_words[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(input_items_dir, 'PG_input_items_added_filter/hard.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join([\" \".join(words) for words in filtered_input_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(generated_sents_dir, 'PG_input_items_added_filter/hard.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join([\"\\t\".join(sents) for sents in filtered_gen_sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
